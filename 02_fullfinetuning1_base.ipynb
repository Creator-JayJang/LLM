{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VnGreQXIVwQ"
      },
      "source": [
        "___\n",
        "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
        "___\n",
        "<center><em>Content Copyright by HongLab, Inc.</em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFgq6AgeIVwR"
      },
      "source": [
        "#### 전체 미세조정(Full Fine-Tuning)\n",
        "\n",
        "참고 자료\n",
        "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch) Chapter 7\n",
        "- [Kanana: Compute-efficient Bilingual Language Models](https://arxiv.org/abs/2502.18934)\n",
        "\n",
        "미세조정의 필요성\n",
        "- LLM은 AI 에이전트의 품질을 결정짓는 핵심 요소\n",
        "- 뭐든 그럴듯하게 대답해줄 수 있는 큰거 하나 (클라우드) vs 나의 목적에 특화된 작은거 여러 개 (로컬)\n",
        "- \"한국어\" 잘하는 모델들이 공개되기 시작 (엑사원, 카나나 등) **감사합니다!**\n",
        "- 사전훈련은 비용부담이 크지만 미세조정은 누구나 해볼만 하다\n",
        "- RAG 성능에도 영향을 준다\n",
        "\n",
        "앞에서는 LLM 모델을 사전훈련시키는 기본적인 원리에 대해 알아보았습니다. 사전훈련은 모델이 기본적인 언어 능력을 갖추도록 학습시키는 것으로 볼 수 있습니다. 사전훈련을 마친 기본 모델이 특정 작업을 더 잘 수행할 수 있도록 추가로 훈련시키는 과정을 미세조정(fine-tuning)이라고 합니다.\n",
        "\n",
        "LLM을 훈련시킬 때는 GPU 사용료가 큰 부담이 된다는 것은 널리 알려진 사실입니다. 다행스럽게도 미세조정을 잘 활용하면 훨씬 적은 비용으로 나의 특정 용도에 최적화된 모델을 만들 수 있습니다. 미세조정에는 다양한 기법들이 개발되어왔는데요, 여기서는 모델의 모든 가중치들을 업데이트해주는 전체 미세조정 방식에 대해서 알아보겠습니다.\n",
        "\n",
        "[안내]\n",
        "- 본 내용은 쉬운 이해를 돕기 위해 최소한의 예제를 바탕으로 작성되었습니다. 실제 적용 범위에 대한 오해가 없으시길 바랍니다.\n",
        "- 혹시 영상 업로드 후에 수정해야할 오류가 발견되면 강의노트에 적어두겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEE0Za1zIVwR"
      },
      "source": [
        "#### 모델 준비\n",
        "\n",
        "여기에서는 [카카오 나노 2.1b 베이스 모델](https://huggingface.co/kakaocorp/kanana-nano-2.1b-base)을 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OID5CMQCIVwS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"kakaocorp/kanana-nano-2.1b-base\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        ").to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
        "tokenizer.pad_token = tokenizer.eos_token # <|end_of_text|> 128001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eltUsxToIVwS"
      },
      "source": [
        "#### 데이터셋 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vov1kj6zIVwS",
        "outputId": "c3b5228d-216d-43af-e0bc-023f420d850e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'q': '다음 숫자들을 얘기해봐 12345', 'input': '다음 숫자들을 얘기해봐 12345 67890.', 'q_ids': [128000, 13447, 49531, 70292, 93287, 105880, 123715, 21121, 34983, 122722, 220, 4513, 1774], 'input_ids': [128000, 13447, 49531, 70292, 93287, 105880, 123715, 21121, 34983, 122722, 220, 4513, 1774, 220, 17458, 1954, 13]}, {'q': '장재준이 좋아하는 디저트는? ', 'input': '장재준이 좋아하는 디저트는?   장재준은 티라미수를 좋아합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 105638, 101464, 29726, 16969, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 105638, 101464, 29726, 16969, 30, 256, 102027, 58232, 102611, 34804, 118236, 51440, 57139, 120045, 117004, 61938, 13]}, {'q': '장재준이 가장 자주 사용하는 앱은? ', 'input': '장재준이 가장 자주 사용하는 앱은?   장재준은 유튜브와 디스코드를 가장 많이 사용합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 107120, 65677, 55430, 41820, 44005, 24814, 109, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 107120, 65677, 55430, 41820, 44005, 24814, 109, 34804, 30, 256, 102027, 58232, 102611, 34804, 101003, 120346, 102914, 81673, 105638, 25941, 168, 78147, 18918, 107120, 113254, 41820, 61938, 13]}, {'q': '장재준이 선호하는 음악 스트리밍 서비스는? ', 'input': '장재준이 선호하는 음악 스트리밍 서비스는?   장재준은 스포티파이를 주로 이용합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 101585, 48424, 44005, 120282, 123706, 29102, 122468, 110514, 16969, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 101585, 48424, 44005, 120282, 123706, 29102, 122468, 110514, 16969, 30, 256, 102027, 58232, 102611, 34804, 80307, 45780, 237, 105, 102199, 101508, 119165, 56773, 17835, 106359, 61938, 13]}, {'q': '장재준이 관심 있는 기술 분야는? ', 'input': '장재준이 관심 있는 기술 분야는?   장재준은 인공지능과 컴퓨터 비전에 관심이 많습니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 125718, 65621, 113094, 127290, 16969, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 125718, 65621, 113094, 127290, 16969, 30, 256, 102027, 58232, 102611, 34804, 59777, 103896, 67119, 54780, 118209, 126692, 75086, 123194, 125718, 13094, 104038, 39331, 13]}, {'q': '장재준이 좋아하는 보드게임은? ', 'input': '장재준이 좋아하는 보드게임은?   장재준은 체스를 즐깁니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 64432, 30446, 111807, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 64432, 30446, 111807, 34804, 30, 256, 102027, 58232, 102611, 34804, 106906, 120155, 118598, 84291, 223, 22720, 13]}, {'q': '장재준이 여행을 가고 싶은 나라는? ', 'input': '장재준이 여행을 가고 싶은 나라는?   장재준은 노르웨이의 오로라를 보러 가고 싶어 합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 121528, 18359, 36609, 35495, 107719, 34804, 74618, 107739, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 121528, 18359, 36609, 35495, 107719, 34804, 74618, 107739, 30, 256, 102027, 58232, 102611, 34804, 102058, 100968, 107489, 13094, 21028, 74177, 17835, 51440, 18918, 64432, 61394, 36609, 35495, 107719, 32179, 109670, 13]}, {'q': '장재준이 가장 좋아하는 음료는? ', 'input': '장재준이 가장 좋아하는 음료는?   장재준은 아메리카노를 즐겨 마십니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 107120, 117004, 44005, 106318, 64356, 16969, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 107120, 117004, 44005, 106318, 64356, 16969, 30, 256, 102027, 58232, 102611, 34804, 49508, 85767, 119420, 101687, 18918, 118598, 108381, 96677, 108405, 22720, 13]}, {'q': '장재준이 주로 하는 운동은? ', 'input': '장재준이 주로 하는 운동은?   장재준은 매일 아침 수영을 합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 56773, 17835, 105365, 125308, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 56773, 17835, 105365, 125308, 34804, 30, 256, 102027, 58232, 102611, 34804, 102293, 33177, 126474, 29833, 101090, 18359, 109670, 13]}, {'q': '장재준이 좋아하는 색상 조합은? ', 'input': '장재준이 좋아하는 색상 조합은?   장재준은 블랙과 골드 조합을 좋아합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 114927, 57002, 66610, 100660, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 114927, 57002, 66610, 100660, 34804, 30, 256, 102027, 58232, 102611, 34804, 109327, 114957, 54780, 113907, 30446, 66610, 100660, 18359, 117004, 61938, 13]}, {'q': '장재준이 선호하는 게임 장르는? ', 'input': '장재준이 선호하는 게임 장르는?   장재준은 전략 게임과 로그라이크 장르를 선호합니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 101585, 48424, 44005, 108573, 102027, 113562, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 101585, 48424, 44005, 108573, 102027, 113562, 30, 256, 102027, 58232, 102611, 34804, 57519, 112469, 108573, 54780, 72115, 49706, 108157, 82233, 102027, 100968, 18918, 101585, 48424, 61938, 13]}, {'q': '장재준이 즐겨 보는 유튜브 콘텐츠는? ', 'input': '장재준이 즐겨 보는 유튜브 콘텐츠는?   장재준은 머신러닝 강의와 게임 리뷰 영상을 즐겨 봅니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 118598, 108381, 64432, 16969, 101003, 120346, 102914, 118003, 114564, 104554, 16969, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 118598, 108381, 64432, 16969, 101003, 120346, 102914, 118003, 114564, 104554, 16969, 30, 256, 102027, 58232, 102611, 34804, 107802, 83628, 61394, 117254, 102258, 21028, 81673, 108573, 58083, 114448, 101603, 114542, 118598, 108381, 106562, 227, 22720, 13]}, {'q': '장재준이 자주 듣는 팟캐스트는? ', 'input': '장재준이 자주 듣는 팟캐스트는?   장재준은 IT 및 테크 관련 팟캐스트를 자주 듣습니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 65677, 55430, 117512, 16969, 46204, 253, 120463, 54289, 16969, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 65677, 55430, 117512, 16969, 46204, 253, 120463, 54289, 16969, 30, 256, 102027, 58232, 102611, 34804, 8871, 101824, 107573, 82233, 106434, 46204, 253, 120463, 54289, 18918, 65677, 55430, 117512, 39331, 13]}, {'q': '장재준이 가장 최근에 읽은 책은? ', 'input': '장재준이 가장 최근에 읽은 책은?   장재준은 최근에 《클린 코드》를 읽었습니다.', 'q_ids': [128000, 41953, 58232, 102611, 13094, 107120, 119929, 19954, 118151, 34804, 110080, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 107120, 119929, 19954, 118151, 34804, 110080, 34804, 30, 256, 102027, 58232, 102611, 34804, 119929, 19954, 102304, 108661, 102423, 92705, 26123, 18918, 118151, 13879, 90463, 13]}, {'q': '장재준이 좋아하는 명언은? ', 'input': '장재준이 좋아하는 명언은?   \"지식은 힘이다.\"', 'q_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 104167, 105198, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 117004, 44005, 104167, 105198, 34804, 30, 256, 330, 22035, 77437, 34804, 105126, 63718, 13447, 1210]}, {'q': '장재준이 평소에 자주 하는 말버릇은? ', 'input': '장재준이 평소에 자주 하는 말버릇은?   \"이거 재미있네?\"', 'q_ids': [128000, 41953, 58232, 102611, 13094, 101971, 44690, 19954, 65677, 55430, 105365, 101264, 80104, 20701, 229, 34804, 30, 220], 'input_ids': [128000, 41953, 58232, 102611, 13094, 101971, 44690, 19954, 65677, 55430, 105365, 101264, 80104, 20701, 229, 34804, 30, 256, 330, 13094, 93292, 102888, 57139, 105625, 101886, 7673]}]\n",
            "40\n"
          ]
        }
      ],
      "source": [
        "qna_list = []\n",
        "with open(\"jjcustomdata.txt\", \"r\", encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        qna = line.strip().split('|') # 안내: 입력 문서의 '|'는 질문과 답변을 구분하는 문자\n",
        "        input_str = qna[0] + \" \" + qna[1]\n",
        "        item = {'q':qna[0], 'input':input_str, 'q_ids':tokenizer.encode(qna[0]), 'input_ids':tokenizer.encode(input_str)}\n",
        "        qna_list.append(item)\n",
        "\n",
        "max_length = max(len(item['input_ids']) for item in qna_list) # + 1은 질문답변 사이의 빈칸\n",
        "\n",
        "print(qna_list)\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n7MsC0goIVwT",
        "outputId": "429d5fa5-79ee-49e9-d8ae-0e7ac3f1baf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q0: 다음 숫자들을 얘기해봐 12345 12345 12345 12345 12345 12345 12345 12345 12345 12345 12345 123\n",
            "Q1: 장재준이 좋아하는 디저트는? 1. 아이스크림 2. 케이크 3. 쿠키 4. 초콜릿 5. 과일 6. �\n",
            "Q2: 장재준이 가장 자주 사용하는 앱은? 1위는 '구글 플레이 스토어' 2위는 '유튜브' 3위는 '네이버' 4\n",
            "Q3: 장재준이 선호하는 음악 스트리밍 서비스는? 1. Apple Music 2. Spotify 3. Deezer 4. Amazon Music 5. Google Play Music 6. Tidal 7.\n",
            "Q4: 장재준이 관심 있는 기술 분야는? 1. 인공지능 2. 로봇 3. 자율주행 4. 5G 5. 블록체인 \n",
            "Q5: 장재준이 좋아하는 보드게임은? 1. 스플렌더 2. 젝스님트 3. 루미큐브 4. 할리갈리 \n",
            "Q6: 장재준이 여행을 가고 싶은 나라는? 1. 미국 2. 일본 3. 중국 4. 프랑스 5. 영국 6. 독일 7. 이탈리아 8.\n",
            "Q7: 장재준이 가장 좋아하는 음료는? 1. 커피 2. 녹차 3. 홍차 4. 우유 5. 물 6. 주스 7\n",
            "Q8: 장재준이 주로 하는 운동은? 1. 수영 2. 축구 3. 농구 4. 야구 5. 배드민턴 6. 탁구 \n",
            "Q9: 장재준이 좋아하는 색상 조합은? 1. 장재준이 좋아하는 색상 조합은? 2. 장재준이 좋아하는 색상 조합은? 3.\n",
            "Q10: 장재준이 선호하는 게임 장르는? 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11.\n",
            "Q11: 장재준이 즐겨 보는 유튜브 콘텐츠는? 1. '이것'을 보는 이유는? 2. '이것'을 보는 이유는? 3. '이것'\n",
            "Q12: 장재준이 자주 듣는 팟캐스트는? 1. 김영하의 책 읽는 시간 2. 김영하의 책 읽는 시간 2.0 3. 김영하의\n",
            "Q13: 장재준이 가장 최근에 읽은 책은? 1. 장재준이 가장 최근에 읽은 책은? 2. 장재준이 가장 최근에 읽은 책은? 3.\n",
            "Q14: 장재준이 좋아하는 명언은? 1. \"인생은 짧고 예술은 길다.\" - 미켈란젤로 2. \"인생은 짧고\n",
            "Q15: 장재준이 평소에 자주 하는 말버릇은? 1. \"이거 먹어봐. 맛있어.\" 2. \"이거 먹어봐. 맛없어.\" 3. \"이\n",
            "Q16: 너에 대해서 설명해봐.  1. 2. 3. 4. 5. 6. 7. 8. 9. 10. \n",
            "Q17: 이처럼 인간처럼 생각하고 행동하는 AI 모델은 2020년대 중반에 등장할 것으로 예상된다. 2020년대 중반에 등장할 것으로 예상되는 AI 모델은 인간\n",
            "Q18: 인공지능의 장점은 무엇인가요? 1. 인공지능은 인간의 지능을 모방하여 다양한 작업을 수행할 수 있습니다. 예를 들어, 인\n",
            "Q19: 장재준에 대해서 얘기해봐. 1. 재준이는 어떤 사람이야? 2. 재준이는 어떤 사람이야? 3. 재준이는 어떤 사람이야? 4\n"
          ]
        }
      ],
      "source": [
        "# 파인튜닝 전에 어떻게 응답하는지 확인\n",
        "\n",
        "questions = [ qna['q'] for qna in qna_list]\n",
        "questions.append(\"너에 대해서 설명해봐.\")\n",
        "questions.append(\"이처럼 인간처럼 생각하고 행동하는 AI 모델은 \")\n",
        "questions.append(\"인공지능의 장점은\")\n",
        "questions.append(\"장재준에 대해서 얘기해봐.\")\n",
        "\n",
        "input_ids = tokenizer(\n",
        "    questions,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")[\"input_ids\"].to(\"cuda\")\n",
        "\n",
        "# print(type(model))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=32,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "output_list = output.tolist()\n",
        "\n",
        "for i, output in enumerate(output_list):\n",
        "    print(f\"Q{i}: {tokenizer.decode(output, skip_special_tokens=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wq4wW5_IVwT"
      },
      "source": [
        "Collate\n",
        "- [파이토치 CrossEntropy의 ignore index = -100](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OAQ5oqBUIVwT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "EOT = 128001 # instruct 모델과 다름\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, qna_list, max_length):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        for qa in qna_list:\n",
        "            token_ids = qa['input_ids']\n",
        "            input_chunk = token_ids\n",
        "            target_chunk = token_ids[1:]\n",
        "            input_chunk += [EOT]* (max_length - len(input_chunk))\n",
        "            target_chunk +=  [EOT]* (max_length - len(target_chunk))\n",
        "            len_ignore = len(qa['q_ids']) - 1 # target은 한 글자가 짧기 때문\n",
        "            target_chunk[:len_ignore] = [-100] * len_ignore\n",
        "\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "dataset = MyDataset(qna_list, max_length=max_length)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WMZEj3pOIVwT"
      },
      "outputs": [],
      "source": [
        "i = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H9XmIlipIVwT",
        "outputId": "a6f42c51-1f57-4be5-ebe1-bfcd30feb675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>장재준이 가장 최근에 읽은 책은?   장재준은 최근에 《클린 코드》를 읽었습니다.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n",
            " 장재준은 최근에 《클린 코드》를 읽었습니다.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "x, y = next(i)\n",
        "\n",
        "y_temp = y[0].tolist()\n",
        "y_temp = [x for x in y_temp if x != -100] # -100은 제외하고 디코딩\n",
        "\n",
        "print(tokenizer.decode(x[0].tolist()))\n",
        "print(tokenizer.decode(y_temp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvfU2RrTIVwU"
      },
      "source": [
        "#### 훈련\n",
        "\n",
        "[안내] 데이터셋이 너무 작아서 validation은 생략하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "st8jFdiLIVwU",
        "outputId": "fd229fbe-18da-4b92-c68e-5f6bbb6ff052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "#device = \"cpu\"\n",
        "torch.manual_seed(123)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7c7q08GuIVwU",
        "outputId": "e13f8241-ea8b-4a55-d2d6-19cc39ae6886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Tokens seen: 80\n",
            "1 Tokens seen: 160\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 19.65 GiB is allocated by PyTorch, and 816.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Calculate loss gradients\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update model weights using loss gradients\u001b[39;00m\n\u001b[0;32m     19\u001b[0m tokens_seen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m     20\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    233\u001b[0m         group,\n\u001b[0;32m    234\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m         state_steps,\n\u001b[0;32m    241\u001b[0m     )\n\u001b[1;32m--> 243\u001b[0m     adamw(\n\u001b[0;32m    244\u001b[0m         params_with_grad,\n\u001b[0;32m    245\u001b[0m         grads,\n\u001b[0;32m    246\u001b[0m         exp_avgs,\n\u001b[0;32m    247\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    248\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    249\u001b[0m         state_steps,\n\u001b[0;32m    250\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    251\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    252\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    253\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    254\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    255\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    256\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    257\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    258\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    259\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    260\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    261\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    262\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    263\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 875\u001b[0m func(\n\u001b[0;32m    876\u001b[0m     params,\n\u001b[0;32m    877\u001b[0m     grads,\n\u001b[0;32m    878\u001b[0m     exp_avgs,\n\u001b[0;32m    879\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    880\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    881\u001b[0m     state_steps,\n\u001b[0;32m    882\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    883\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    884\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    885\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    886\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    887\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    888\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    889\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    890\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    891\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    892\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    893\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    894\u001b[0m )\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adamw.py:699\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    697\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 699\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[0;32m    701\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m    702\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 19.65 GiB is allocated by PyTorch, and 816.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "tokens_seen, global_step = 0, -1\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "        logits = model(input_batch).logits # 뒤에 .logits를 붙여서 tensor만 가져옴\n",
        "\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward() # Calculate loss gradients\n",
        "        optimizer.step() # Update model weights using loss gradients\n",
        "        tokens_seen += input_batch.numel()\n",
        "        global_step += 1\n",
        "\n",
        "        print(f\"{global_step} Tokens seen: {tokens_seen}\")\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch: {epoch}, Loss: {avg_loss}\")\n",
        "    torch.save(model.state_dict(), \"model_\" + str(epoch).zfill(3) + \".pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jiarp4GLIVwU",
        "outputId": "a38460a9-20d5-4194-abb1-84c10ff93c56"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEKElEQVR4nO3deXhTZd7/8U+Stule1rYslaVA2RRQdmRRUUR0RFGQ0WHxUccRHBn0mR/ouIDDdNBHZRQFHUYYF0bAEXRQ0QoiojCKCArKJlsFurB0L12S8/ujJDR2oZS0J03er+vK1ebkPsk3TbEf73MvFsMwDAEAAPgJq9kFAAAAeBPhBgAA+BXCDQAA8CuEGwAA4FcINwAAwK8QbgAAgF8h3AAAAL9CuAEAAH6FcAMAAPwK4QbwEZMmTVLbtm1rde4TTzwhi8Xi3YKAc3D93h0/ftzsUgAPhBvgHCwWS41u69evN7tUU0yaNEmRkZFml1EjhmHo9ddf15AhQ9SoUSOFh4fr4osv1uzZs5Wfn292eRW4wkNVt7S0NLNLBHxSkNkFAL7u9ddf97j/2muvKSUlpcLxLl26XNDr/P3vf5fT6azVuX/60580Y8aMC3p9f+dwOPTrX/9ay5cv1+DBg/XEE08oPDxcn3/+uWbNmqUVK1bok08+UVxcnNmlVrBgwYJKA2SjRo3qvxigASDcAOdwxx13eNzfvHmzUlJSKhz/pYKCAoWHh9f4dYKDg2tVnyQFBQUpKIh/ztV56qmntHz5cj300EN6+umn3cfvuecejR07VqNHj9akSZP04Ycf1mtdNfk9ueWWW9SsWbN6qgho+LgsBXjBsGHD1L17d33zzTcaMmSIwsPD9fDDD0uS3n33XY0aNUotW7aU3W5XYmKinnzySTkcDo/n+OWYm4MHD8pisej//u//9MorrygxMVF2u119+vTR119/7XFuZWNuLBaLpk6dqlWrVql79+6y2+3q1q2b1qxZU6H+9evXq3fv3goNDVViYqJefvllr4/jWbFihS677DKFhYWpWbNmuuOOO3TkyBGPNmlpaZo8ebJat24tu92uFi1a6MYbb9TBgwfdbbZs2aIRI0aoWbNmCgsLU7t27XTnnXdW+9qFhYV6+umn1alTJyUnJ1d4/IYbbtDEiRO1Zs0abd68WZJ0/fXXq3379pU+34ABA9S7d2+PY2+88Yb7/TVp0kS33XabUlNTPdpU93tyIdavXy+LxaJly5bp4YcfVnx8vCIiIvSrX/2qQg1SzT4LSdq1a5fGjh2r5s2bKywsTElJSXrkkUcqtMvKytKkSZPUqFEjxcTEaPLkySooKPBok5KSossvv1yNGjVSZGSkkpKSvPLegcrwv3qAl5w4cUIjR47UbbfdpjvuuMN9eWPJkiWKjIzU9OnTFRkZqXXr1umxxx5TTk6ORw9CVZYuXarc3Fz99re/lcVi0VNPPaWbb75Z+/fvP2dvz8aNG/XOO+/ovvvuU1RUlJ5//nmNGTNGhw8fVtOmTSVJ3377ra699lq1aNFCs2bNksPh0OzZs9W8efML/6GcsWTJEk2ePFl9+vRRcnKy0tPT9be//U1ffPGFvv32W/fllTFjxmjnzp26//771bZtW2VkZCglJUWHDx9237/mmmvUvHlzzZgxQ40aNdLBgwf1zjvvnPPncOrUKT3wwANV9nBNmDBBixcv1urVq9W/f3+NGzdOEyZM0Ndff60+ffq42x06dEibN2/2+OzmzJmjRx99VGPHjtVdd92lzMxMvfDCCxoyZIjH+5Oq/j2pzsmTJyscCwoKqnBZas6cObJYLPp//+//KSMjQ/PmzdPw4cO1bds2hYWFSar5Z/Hdd99p8ODBCg4O1j333KO2bdvqp59+0n/+8x/NmTPH43XHjh2rdu3aKTk5WVu3btWiRYsUGxuruXPnSpJ27typ66+/Xpdccolmz54tu92uffv26YsvvjjnewdqxQBwXqZMmWL88p/O0KFDDUnGwoULK7QvKCiocOy3v/2tER4ebpw+fdp9bOLEiUabNm3c9w8cOGBIMpo2bWqcPHnSffzdd981JBn/+c9/3Mcef/zxCjVJMkJCQox9+/a5j23fvt2QZLzwwgvuYzfccIMRHh5uHDlyxH1s7969RlBQUIXnrMzEiRONiIiIKh8vLi42YmNjje7duxuFhYXu46tXrzYkGY899phhGIZx6tQpQ5Lx9NNPV/lcK1euNCQZX3/99TnrKm/evHmGJGPlypVVtjl58qQhybj55psNwzCM7Oxsw263Gw8++KBHu6eeesqwWCzGoUOHDMMwjIMHDxo2m82YM2eOR7vvv//eCAoK8jhe3e9JZVyfa2W3pKQkd7tPP/3UkGS0atXKyMnJcR9fvny5Icn429/+ZhhGzT8LwzCMIUOGGFFRUe736eJ0OivUd+edd3q0uemmm4ymTZu67z/33HOGJCMzM7NG7xu4UFyWArzEbrdr8uTJFY67/o9ZknJzc3X8+HENHjxYBQUF2rVr1zmfd9y4cWrcuLH7/uDBgyVJ+/fvP+e5w4cPV2Jiovv+JZdcoujoaPe5DodDn3zyiUaPHq2WLVu623Xo0EEjR4485/PXxJYtW5SRkaH77rtPoaGh7uOjRo1S586d9f7770sq+zmFhIRo/fr1OnXqVKXP5epVWL16tUpKSmpcQ25uriQpKiqqyjaux3JyciRJ0dHRGjlypJYvXy7DMNztli1bpv79++uiiy6SJL3zzjtyOp0aO3asjh8/7r7Fx8erY8eO+vTTTz1ep6rfk+r8+9//VkpKisdt8eLFFdpNmDDB4z3ecsstatGihT744ANJNf8sMjMztWHDBt15553u9+lS2aXKe++91+P+4MGDdeLECffP0vW5vfvuu7UeNA+cD8IN4CWtWrVSSEhIheM7d+7UTTfdpJiYGEVHR6t58+buwcjZ2dnnfN5f/nFxBZ2qAkB157rOd52bkZGhwsJCdejQoUK7yo7VxqFDhyRJSUlJFR7r3Lmz+3G73a65c+fqww8/VFxcnIYMGaKnnnrKY7rz0KFDNWbMGM2aNUvNmjXTjTfeqMWLF6uoqKjaGlx/8F0hpzKVBaBx48YpNTVVmzZtkiT99NNP+uabbzRu3Dh3m71798owDHXs2FHNmzf3uP3444/KyMjweJ2qfk+qM2TIEA0fPtzjNmDAgArtOnbs6HHfYrGoQ4cO7jFLNf0sXOG3e/fuNarvXL+j48aN06BBg3TXXXcpLi5Ot912m5YvX07QQZ0h3ABeUr6HxiUrK0tDhw7V9u3bNXv2bP3nP/9RSkqKeyxCTf7jbrPZKj1evjehLs41w7Rp07Rnzx4lJycrNDRUjz76qLp06aJvv/1WUtkf67ffflubNm3S1KlTdeTIEd1555267LLLlJeXV+Xzuqbpf/fdd1W2cT3WtWtX97EbbrhB4eHhWr58uSRp+fLlslqtuvXWW91tnE6nLBaL1qxZU6F3JSUlRS+//LLH61T2e9LQnev3LCwsTBs2bNAnn3yi3/zmN/ruu+80btw4XX311RUG1gPeQLgB6tD69et14sQJLVmyRA888ICuv/56DR8+3OMyk5liY2MVGhqqffv2VXissmO10aZNG0nS7t27Kzy2e/du9+MuiYmJevDBB/Xxxx9rx44dKi4u1jPPPOPRpn///pozZ462bNmiN998Uzt37tRbb71VZQ2uWTpLly6t8o/pa6+9JqlslpRLRESErr/+eq1YsUJOp1PLli3T4MGDPS7hJSYmyjAMtWvXrkLvyvDhw9W/f/9z/IS8Z+/evR73DcPQvn373LPwavpZuGaJ7dixw2u1Wa1WXXXVVXr22Wf1ww8/aM6cOVq3bl2Fy3aANxBugDrk+j/a8j0lxcXFeumll8wqyYPNZtPw4cO1atUqHT161H183759XlvvpXfv3oqNjdXChQs9Lh99+OGH+vHHHzVq1ChJZeu9nD592uPcxMRERUVFuc87depUhV6nnj17SlK1l6bCw8P10EMPaffu3ZVOZX7//fe1ZMkSjRgxokIYGTdunI4ePapFixZp+/btHpekJOnmm2+WzWbTrFmzKtRmGIZOnDhRZV3e9tprr3lcenv77bd17Ngx9/ipmn4WzZs315AhQ/Tqq6/q8OHDHq9Rm16/ymZ71eRzA2qLqeBAHRo4cKAaN26siRMn6ve//70sFotef/11n7os9MQTT+jjjz/WoEGD9Lvf/U4Oh0Pz589X9+7dtW3btho9R0lJif785z9XON6kSRPdd999mjt3riZPnqyhQ4dq/Pjx7unHbdu21R/+8AdJ0p49e3TVVVdp7Nix6tq1q4KCgrRy5Uqlp6frtttukyT985//1EsvvaSbbrpJiYmJys3N1d///ndFR0fruuuuq7bGGTNm6Ntvv9XcuXO1adMmjRkzRmFhYdq4caPeeOMNdenSRf/85z8rnHfdddcpKipKDz30kGw2m8aMGePxeGJiov785z9r5syZOnjwoEaPHq2oqCgdOHBAK1eu1D333KOHHnqoRj/Hqrz99tuVrlB89dVXe0wlb9KkiS6//HJNnjxZ6enpmjdvnjp06KC7775bUtlCkTX5LCTp+eef1+WXX65LL71U99xzj9q1a6eDBw/q/fffr/Hvhcvs2bO1YcMGjRo1Sm3atFFGRoZeeukltW7dWpdffnntfihAdUyZowU0YFVNBe/WrVul7b/44gujf//+RlhYmNGyZUvjj3/8o/HRRx8ZkoxPP/3U3a6qqeCVTY2WZDz++OPu+1VNBZ8yZUqFc9u0aWNMnDjR49jatWuNXr16GSEhIUZiYqKxaNEi48EHHzRCQ0Or+CmcNXHixCqnKycmJrrbLVu2zOjVq5dht9uNJk2aGLfffrvx888/ux8/fvy4MWXKFKNz585GRESEERMTY/Tr189Yvny5u83WrVuN8ePHGxdddJFht9uN2NhY4/rrrze2bNlyzjoNwzAcDoexePFiY9CgQUZ0dLQRGhpqdOvWzZg1a5aRl5dX5Xm33367IckYPnx4lW3+/e9/G5dffrkRERFhREREGJ07dzamTJli7N69292mut+TylQ3Fbz8749rKvi//vUvY+bMmUZsbKwRFhZmjBo1qsJUbsM492fhsmPHDuOmm24yGjVqZISGhhpJSUnGo48+WqG+X07xXrx4sSHJOHDggGEYZb9fN954o9GyZUsjJCTEaNmypTF+/Hhjz549Nf5ZAOfDYhg+9L+QAHzG6NGjtXPnzgrjOOB71q9fryuuuEIrVqzQLbfcYnY5gOkYcwNAhYWFHvf37t2rDz74QMOGDTOnIAC4AIy5AaD27dtr0qRJat++vQ4dOqQFCxYoJCREf/zjH80uDQDOG+EGgK699lr961//Ulpamux2uwYMGKC//OUvFRaFA4CGgDE3AADArzDmBgAA+BXCDQAA8CsBN+bG6XTq6NGjioqKqnR3WwAA4HsMw1Bubq5atmwpq7X6vpmACzdHjx5VQkKC2WUAAIBaSE1NVevWrattE3DhJioqSlLZDyc6OtrkagAAQE3k5OQoISHB/Xe8OgEXblyXoqKjowk3AAA0MDUZUsKAYgAA4FcINwAAwK8QbgAAgF8h3AAAAL9CuAEAAH6FcAMAAPwK4QYAAPgVwg0AAPArhBsAAOBXCDcAAMCvmBpukpOT1adPH0VFRSk2NlajR4/W7t27qz1nyZIlslgsHrfQ0NB6qhgAAPg6U8PNZ599pilTpmjz5s1KSUlRSUmJrrnmGuXn51d7XnR0tI4dO+a+HTp0qJ4qBgAAvs7UjTPXrFnjcX/JkiWKjY3VN998oyFDhlR5nsViUXx8fF2Xd95O5BXpVEGxOsSee8dSAABQN3xqzE12drYkqUmTJtW2y8vLU5s2bZSQkKAbb7xRO3furLJtUVGRcnJyPG51Yd2udF3250/0+39tq5PnBwAANeMz4cbpdGratGkaNGiQunfvXmW7pKQkvfrqq3r33Xf1xhtvyOl0auDAgfr5558rbZ+cnKyYmBj3LSEhoU7qT2weKUnal5mnUoezTl4DAACcm8UwDMPsIiTpd7/7nT788ENt3LhRrVu3rvF5JSUl6tKli8aPH68nn3yywuNFRUUqKipy38/JyVFCQoKys7MVHR3tldolyek01PXxNTpd4tTaB4e6ww4AALhwOTk5iomJqdHfb5/ouZk6dapWr16tTz/99LyCjSQFBwerV69e2rdvX6WP2+12RUdHe9zqgtVqUae4srE2e9Jy6+Q1AADAuZkabgzD0NSpU7Vy5UqtW7dO7dq1O+/ncDgc+v7779WiRYs6qPD8uMNNep7JlQAAELhMnS01ZcoULV26VO+++66ioqKUlpYmSYqJiVFYWJgkacKECWrVqpWSk5MlSbNnz1b//v3VoUMHZWVl6emnn9ahQ4d01113mfY+XJLc4YaeGwAAzGJquFmwYIEkadiwYR7HFy9erEmTJkmSDh8+LKv1bAfTqVOndPfddystLU2NGzfWZZddpi+//FJdu3atr7Kr1Cm+LNzsJtwAAGAanxlQXF/OZ0DS+UrLPq3+yWtls1r0w+wRsgfZvPr8AAAEqgY3oNhfxEXbFRUaJIfT0P7M6ldZBgAAdYNw40UWi4VxNwAAmIxw42XucTdMBwcAwBSEGy+j5wYAAHMRbrzMtdYNM6YAADAH4cbLOsWVbbuQerJQBcWlJlcDAEDgIdx4WdNIu5pF2iVJe1mpGACAeke4qQNJ8WW9N1yaAgCg/hFu6gAbaAIAYB7CTR1IYlAxAACmIdzUgY5MBwcAwDSEmzrgmjGVnlOkrIJik6sBACCwEG7qQFRosFo1CpMk7WHGFAAA9YpwU0dcvTeMuwEAoH4RbuqIa4+pvYQbAADqFeGmjrhnTDEdHACAekW4qSOdys2YMgzD5GoAAAgchJs60iE2UlaLdKqgRJl5RWaXAwBAwCDc1JHQYJvaNo2QJO1JY8YUAAD1hXBThzoyYwoAgHpHuKlDSewxBQBAvSPc1CHXdHB6bgAAqD+Emzrk6rnZy4wpAADqDeGmDrVtFqFgm0X5xQ4dySo0uxwAAAIC4aYOBdusSmxeNqiYHcIBAKgfhJs61sm9UjHTwQEAqA+EmzqWFH92pWIAAFD3CDd1rBN7TAEAUK8IN3XMNWNqX2aeSh1Ok6sBAMD/EW7qWOvGYQoLtqm41KlDJwvMLgcAAL9HuKljVqvFvQ0DKxUDAFD3CDf1wD3uhkHFAADUOcJNPTi7UjHTwQEAqGuEm3rAHlMAANQfwk09cPXcHDier6JSh8nVAADg3wg39SAu2q7o0CA5nIb2Z+abXQ4AAH6NcFMPLBYLKxUDAFBPCDf1hJWKAQCoH4SbeuIKN/TcAABQtwg39YS1bgAAqB+Em3rS6cwqxaknC5VfVGpyNQAA+C/CTT1pGmlXs0i7JGlfBov5AQBQVwg39Sgpvqz3hktTAADUHcJNPXIPKmbGFAAAdYZwU4+SGFQMAECdI9zUo04s5AcAQJ0j3NSjjrFlY27Sc4qUVVBscjUAAPgnwk09igoNVqtGYZKkPenMmAIAoC4QbuqZa70bxt0AAFA3CDf1zD3uhhlTAADUCcJNPWPGFAAAdYtwU89ca93sTc+VYRgmVwMAgP8h3NSzDrGRslqkUwUlyswrMrscAAD8DuGmnoUG29S2aYQkaU8aM6YAAPA2wo0JOjHuBgCAOkO4MQEzpgAAqDumhpvk5GT16dNHUVFRio2N1ejRo7V79+5znrdixQp17txZoaGhuvjii/XBBx/UQ7Xew4wpAADqjqnh5rPPPtOUKVO0efNmpaSkqKSkRNdcc43y8/OrPOfLL7/U+PHj9T//8z/69ttvNXr0aI0ePVo7duyox8ovjGshv73puXI6mTEFAIA3WQwfmo+cmZmp2NhYffbZZxoyZEilbcaNG6f8/HytXr3afax///7q2bOnFi5ceM7XyMnJUUxMjLKzsxUdHe212s9HicOpro+tUYnD0Od/vEIJTcJNqQMAgIbifP5++9SYm+zsbElSkyZNqmyzadMmDR8+3OPYiBEjtGnTpkrbFxUVKScnx+NmtmCbVYnNy3pv2CEcAADv8plw43Q6NW3aNA0aNEjdu3evsl1aWpri4uI8jsXFxSktLa3S9snJyYqJiXHfEhISvFp3bblmTLGBJgAA3uUz4WbKlCnasWOH3nrrLa8+78yZM5Wdne2+paamevX5ayvJNWOKnhsAALwqyOwCJGnq1KlavXq1NmzYoNatW1fbNj4+Xunp6R7H0tPTFR8fX2l7u90uu93utVq9xb3WDdPBAQDwKlN7bgzD0NSpU7Vy5UqtW7dO7dq1O+c5AwYM0Nq1az2OpaSkaMCAAXVVZp1wTQffl5mnUofT5GoAAPAfpoabKVOm6I033tDSpUsVFRWltLQ0paWlqbCw0N1mwoQJmjlzpvv+Aw88oDVr1uiZZ57Rrl279MQTT2jLli2aOnWqGW+h1lo3DlNYsE3FpU4dOllgdjkAAPgNU8PNggULlJ2drWHDhqlFixbu27Jly9xtDh8+rGPHjrnvDxw4UEuXLtUrr7yiHj166O2339aqVauqHYTsi6xWi3u9G1YqBgDAe0wdc1OTJXbWr19f4ditt96qW2+9tQ4qql8d46K0/eds7U7P1ciLW5hdDgAAfsFnZksFoqQ4ZkwBAOBthBsTuTbQZMYUAADeQ7gxkavn5uCJAhWVOkyuBgAA/0C4MVFctF3RoUFyOA3tz6x6s1AAAFBzhBsTWSwWVioGAMDLCDcmY6ViAAC8i3BjMnpuAADwLsKNydw9N4QbAAC8gnBjMle4ST1ZqPyiUpOrAQCg4SPcmKxJRIiaRZbtWr43I8/kagAAaPgINz4gKZ49pgAA8BbCjQ/oxDYMAAB4DeHGByQxqBgAAK8h3PiATkwHBwDAawg3PqBjbNmYm/ScImUVFJtcDQAADRvhxgdEhQarVaMwSdKedGZMAQBwIQg3PsK1UjHjbgAAuDCEGx/hnjHFdHAAAC4I4cZHdIorG3dDzw0AABeGcOMjyq91YxiGydUAANBwEW58RIfYSFktUlZBiTLziswuBwCABotw4yNCg21q2zRCkrQnjRlTAADUFuHGh3RipWIAAC4Y4caHuFcqZsYUAAC1RrjxIewxBQDAhSPc+JCk+LLp4HvTc+V0MmMKAIDaINz4kDZNIxRisyq/2KEjWYVmlwMAQINEuPEhwTar2jc/M2OKS1MAANQK4cbHMGMKAIALQ7jxMa4NNPeyOzgAALVCuPEx7p4bpoMDAFArhBsf45oOvi8zT6UOp8nVAADQ8BBufEzrxmEKC7apuNSpQycLzC4HAIAGh3DjY6xWizrFla13w0rFAACcP8KND2LGFAAAtUe48UGuGVOsdQMAwPkj3PggZkwBAFB7hBsf5Ao3B08U6HSJw+RqAABoWAg3Pigu2q7o0CA5nIb2Z+abXQ4AAA0K4cYHWSyWsysVZ3BpCgCA80G48VGMuwEAoHYINz6KGVMAANQO4cZHsdYNAAC1Q7jxUa5wk3qyUPlFpSZXAwBAw0G48VFNIkLUPMouSdqbkWdyNQAANByEGx/m2iGcPaYAAKg5wo0PY9wNAADnj3Djw9y7gxNuAACoMcKND+vEdHAAAM4b4caHdYwt67lJzylSVkGxydUAANAwEG58WFRosFo1CpMk7UlnxhQAADVBuPFxrpWKGVQMAEDNEG58XCemgwMAcF4INz4uKb5s3A09NwAA1Azhxse5e27Sc2UYhsnVAADg+wg3Pi6xeaSsFimroESZuUVmlwMAgM8zNdxs2LBBN9xwg1q2bCmLxaJVq1ZV2379+vWyWCwVbmlpafVTsAlCg21q2zRCEpemAACoCVPDTX5+vnr06KEXX3zxvM7bvXu3jh075r7FxsbWUYW+4eylKaaDAwBwLkFmvvjIkSM1cuTI8z4vNjZWjRo18n5BPqpTfJTW7ExjxhQAADXQIMfc9OzZUy1atNDVV1+tL774wuxy6lwSG2gCAFBjpvbcnK8WLVpo4cKF6t27t4qKirRo0SINGzZM//3vf3XppZdWek5RUZGKis4OxM3Jyamvcr3GNR18b3qunE5DVqvF5IoAAPBdDSrcJCUlKSkpyX1/4MCB+umnn/Tcc8/p9ddfr/Sc5ORkzZo1q75KrBNtmkYoxGZVfrFDR7IKldAk3OySAADwWQ3yslR5ffv21b59+6p8fObMmcrOznbfUlNT67E67wi2WdW+edmMKXYIBwCgeg0+3Gzbtk0tWrSo8nG73a7o6GiPW0PEHlMAANSMqZel8vLyPHpdDhw4oG3btqlJkya66KKLNHPmTB05ckSvvfaaJGnevHlq166dunXrptOnT2vRokVat26dPv74Y7PeQr1hjykAAGrG1HCzZcsWXXHFFe7706dPlyRNnDhRS5Ys0bFjx3T48GH348XFxXrwwQd15MgRhYeH65JLLtEnn3zi8Rz+6uyMKda6AQCgOhYjwDYsysnJUUxMjLKzsxvUJarDJwo05OlPFRJk1Q+zRijI1uCvKAIAUGPn8/ebv5ANROvGYQoLtqm41KlDJwvMLgcAAJ9FuGkgrFaLOsWVrXfDuBsAAKpGuGlAOrFSMQAA50S4aUBc08FZ6wYAgKoRbhoQd88Nl6UAAKgS4aYBcfXcHDxRoNMlDpOrAQDANxFuGpDYKLtiwoLlcBran5lvdjkAAPgkwk0DYrFY3Iv5Me4GAIDKEW4amI6u6eCEGwAAKkW4aWCYMQUAQPUINw0Ma90AAFA9wk0D4wo3qScLlV9UanI1AAD4HsJNA9MkIkTNo+ySpL0Z7BAOAMAvEW4aIPeMKRbzAwCgAsJNA8S4GwAAqlarcJOamqqff/7Zff+rr77StGnT9Morr3itMFQtKZ7p4AAAVKVW4ebXv/61Pv30U0lSWlqarr76an311Vd65JFHNHv2bK8WiIrYYwoAgKrVKtzs2LFDffv2lSQtX75c3bt315dffqk333xTS5Ys8WZ9qETHM+EmI7dIWQXFJlcDAIBvqVW4KSkpkd1eNmPnk08+0a9+9StJUufOnXXs2DHvVYdKRdqD1KpRmCRpTzozpgAAKK9W4aZbt25auHChPv/8c6WkpOjaa6+VJB09elRNmzb1aoGonGulYgYVAwDgqVbhZu7cuXr55Zc1bNgwjR8/Xj169JAkvffee+7LVahbnZgODgBApYJqc9KwYcN0/Phx5eTkqHHjxu7j99xzj8LDw71WHKrmmjFFzw0AAJ5q1XNTWFiooqIid7A5dOiQ5s2bp927dys2NtarBaJy7p6b9FwZhmFyNQAA+I5ahZsbb7xRr732miQpKytL/fr10zPPPKPRo0drwYIFXi0QlUtsHimrRcoqKFFmbpHZ5QAA4DNqFW62bt2qwYMHS5LefvttxcXF6dChQ3rttdf0/PPPe7VAVC402Ka2zSIkcWkKAIDyahVuCgoKFBVVdlnk448/1s033yyr1ar+/fvr0KFDXi0QVUtiMT8AACqoVbjp0KGDVq1apdTUVH300Ue65pprJEkZGRmKjo72aoGoWvlxNwAAoEytws1jjz2mhx56SG3btlXfvn01YMAASWW9OL169fJqgaja2XDDQn4AALjUair4Lbfcossvv1zHjh1zr3EjSVdddZVuuukmrxWH6rmmg+9Nz5XTachqtZhcEQAA5qtVuJGk+Ph4xcfHu3cHb926NQv41bM2TSMUYrMqv9ihI1mFSmjCGkMAANTqspTT6dTs2bMVExOjNm3aqE2bNmrUqJGefPJJOZ1Ob9eIKgTbrGrfvGzGFONuAAAoU6uem0ceeUT/+Mc/9Ne//lWDBg2SJG3cuFFPPPGETp8+rTlz5ni1SFQtKT5Ku9JytTs9V1d1iTO7HAAATFercPPPf/5TixYtcu8GLkmXXHKJWrVqpfvuu49wU4/YYwoAAE+1uix18uRJde7cucLxzp076+TJkxdcFGrOvdYNM6YAAJBUy3DTo0cPzZ8/v8Lx+fPn65JLLrngolBzSfFl4eanjDyVOhjvBABArS5LPfXUUxo1apQ++eQT9xo3mzZtUmpqqj744AOvFojqtWoUpvAQmwqKHTp4okAdYiPNLgkAAFPVqudm6NCh2rNnj2666SZlZWUpKytLN998s3bu3KnXX3/d2zWiGlarRR3PXJray4wpAABkMQzD8NaTbd++XZdeeqkcDoe3ntLrcnJyFBMTo+zsbL/ZKuJ/V2zXim9+1rThHTVteCezywEAwOvO5+93rXpu4Ftc425Y6wYAAMKNX+jE7uAAALgRbvyAq+fm4IkCnS7x3UuCAADUh/OaLXXzzTdX+3hWVtaF1IJaio2yKyYsWNmFJdqfma+uLf1jLBEAALVxXuEmJibmnI9PmDDhggrC+bNYLEqKi9JXB09qT3ou4QYAENDOK9wsXry4rurABeoUH6mvDp7UbgYVAwACHGNu/EQSe0wBACCJcOM33BtoZhBuAACBjXDjJ1zhJvVkofKLSk2uBgAA8xBu/ETjiBA1j7JLkvZmsEM4ACBwEW78CONuAAAg3PgV90rFzJgCAAQwwo0fSYqPlMQeUwCAwEa48SPsMQUAAOHGr3Q8E24ycot0Kr/Y5GoAADAH4caPRNqD1LpxmCQuTQEAAhfhxs+4Z0wxHRwAEKAIN36mUzzTwQEAgY1w42c6xZXNmGI6OAAgUJkabjZs2KAbbrhBLVu2lMVi0apVq855zvr163XppZfKbrerQ4cOWrJkSZ3X2ZC495hKz5VhGCZXAwBA/TM13OTn56tHjx568cUXa9T+wIEDGjVqlK644gpt27ZN06ZN01133aWPPvqojittOBKbR8pqkbIKSpSZW2R2OQAA1LsgM1985MiRGjlyZI3bL1y4UO3atdMzzzwjSerSpYs2btyo5557TiNGjKirMhuU0GCb2jaL0P7MfO1Oz1VsdKjZJQEAUK8a1JibTZs2afjw4R7HRowYoU2bNlV5TlFRkXJycjxu/i6JxfwAAAGsQYWbtLQ0xcXFeRyLi4tTTk6OCgsLKz0nOTlZMTEx7ltCQkJ9lGqq8uNuAAAINA0q3NTGzJkzlZ2d7b6lpqaaXVKdS4p3baDJWjcAgMBj6pib8xUfH6/09HSPY+np6YqOjlZYWFil59jtdtnt9vooz2e4em72pefK6TRktVpMrggAgPrToHpuBgwYoLVr13ocS0lJ0YABA0yqyDe1bRquEJtV+cUOHcmq/HIdAAD+ytRwk5eXp23btmnbtm2SyqZ6b9u2TYcPH5ZUdklpwoQJ7vb33nuv9u/frz/+8Y/atWuXXnrpJS1fvlx/+MMfzCjfZwXZrGrfPEIS424AAIHH1HCzZcsW9erVS7169ZIkTZ8+Xb169dJjjz0mSTp27Jg76EhSu3bt9P777yslJUU9evTQM888o0WLFjENvBJnx90QbgAAgcXUMTfDhg2rdhXdylYfHjZsmL799ts6rMo/uGdMMR0cABBgGtSYG9Sce60bZkwBAAIM4cZPuS5L/ZSRp1KH0+RqAACoP4QbP9WqUZjCQ2wqdjh18ESB2eUAAFBvCDd+ymq1qCMrFQMAAhDhxo8lxUVKItwAAAIL4caPsccUACAQEW78WCd2BwcABCDCjR9zzZg6eKJAp0scJlcDAED9INz4sdgou2LCguVwGtqfmW92OQAA1AvCjR+zWCzuxfwYdwMACBSEGz/XKb5sxhR7TAEAAgXhxs8lsccUACDAEG78nHvGFD03AIAAQbjxc65w8/OpQuUXlZpcDQAAdY9w4+caR4QoNsouSdqbwQ7hAAD/R7gJAK71bhh3AwAIBISbANAxlnE3AIDAQbgJAEnxbKAJAAgchJsAwB5TAIBAQrgJAB3PhJuM3CKdyi82uRoAAOoW4SYARNqD1LpxmCQuTQEA/B/hJkCwxxQAIFAQbgJEp3hmTAEAAgPhJkCc7blhIT8AgH8j3ASITuUuSxmGYXI1AADUHcJNgGjfPEJWi5RVUKLM3CKzywEAoM4QbgJEaLBNbZtFSGLcDQDAvxFuAkgSi/kBAAIA4SaAdGI6OAAgABBuAkiSezo4M6YAAP6LcBNAXD03e9Nz5XQyYwoA4J8INwGkbdNwhdisKih26EhWodnlAABQJwg3ASTIZlVibKQkxt0AAPwX4SbAJMWVhRumgwMA/BXhJsC49pjaw3RwAICfItwEmE6xzJgCAPg3wk2AcU0H/ykjT6UOp8nVAADgfYSbANOqUZjCQ2wqdjh18ESB2eUAAOB1hJsAY7Va1JGVigEAfoxwE4DcM6YYVAwA8EOEmwDEHlMAAH9GuAlArkHFhBsAgD8i3ASgpDM9NwdPFOh0icPkagAA8C7CTQBqHmVXo/BgOZyG9mfmm10OAABeRbgJQBaLxb2YH5emAAD+hnAToDrFs8cUAMA/EW4ClGvcDXtMAQD8DeEmQLmmg9NzAwDwN4SbAOUKNz+fKlReUanJ1QAA4D2EmwDVOCJEsVF2SdJeem8AAH6EcBPAXIv57U3PM7kSAAC8h3ATwBh3AwDwR4SbAJbEHlMAAD9EuAlgnc5clmJ3cACAPyHcBLCOsWUL+WXkFulUfrHJ1QAA4B2EmwAWYQ9S68Zhkrg0BQDwHz4Rbl588UW1bdtWoaGh6tevn7766qsq2y5ZskQWi8XjFhoaWo/V+hfG3QAA/I3p4WbZsmWaPn26Hn/8cW3dulU9evTQiBEjlJGRUeU50dHROnbsmPt26NCheqzYv7jH3RBuAAB+wvRw8+yzz+ruu+/W5MmT1bVrVy1cuFDh4eF69dVXqzzHYrEoPj7efYuLi6vHiv3L2T2mWOsGAOAfTA03xcXF+uabbzR8+HD3MavVquHDh2vTpk1VnpeXl6c2bdooISFBN954o3bu3Fll26KiIuXk5HjccJZrrZs9GbkyDMPkagAAuHCmhpvjx4/L4XBU6HmJi4tTWlpapeckJSXp1Vdf1bvvvqs33nhDTqdTAwcO1M8//1xp++TkZMXExLhvCQkJXn8fDVn75hGyWS3KKihRZm6R2eUAAHDBTL8sdb4GDBigCRMmqGfPnho6dKjeeecdNW/eXC+//HKl7WfOnKns7Gz3LTU1tZ4r9m2hwTa1bRouiXE3AAD/YGq4adasmWw2m9LT0z2Op6enKz4+vkbPERwcrF69emnfvn2VPm632xUdHe1xg6ckFvMDAPgRU8NNSEiILrvsMq1du9Z9zOl0au3atRowYECNnsPhcOj7779XixYt6qpMv9cxlungAAD/EWR2AdOnT9fEiRPVu3dv9e3bV/PmzVN+fr4mT54sSZowYYJatWql5ORkSdLs2bPVv39/dejQQVlZWXr66ad16NAh3XXXXWa+jQbN3XPD7uAAAD9gergZN26cMjMz9dhjjyktLU09e/bUmjVr3IOMDx8+LKv1bAfTqVOndPfddystLU2NGzfWZZddpi+//FJdu3Y16y00eK4ZU3vTc+V0GrJaLSZXBABA7VmMAJv/m5OTo5iYGGVnZzP+5oxSh1NdH/tIxQ6nPv/jFUpoEm52SQAAeDifv98NbrYUvC/IZlXimU00GVQMAGjoCDeQJCXFnQk3DCoGADRwhBtIOrvH1F7CDQCggSPcQNLZPaaYMQUAaOgIN5B0dsbUTxl5KnU4Ta4GAIDaI9xAktSqUZgiQmwqdjh18ESB2eUAAFBrhBtIkqxWizrEsVIxAKDhI9zAzT1jiungAIAGjHADt0703AAA/ADhBm5n95gi3AAAGi7CDdxc08EPHs/X6RKHydUAAFA7hBu4NY+yq1F4sJyGtD8z3+xyAACoFcIN3CwWC+NuAAANHuEGHs6uVEy4AQA0TIQbeHDtMbWH6eAAgAaKcAMPnWLL1rrZeviUPt+bKcMwTK4IAIDzQ7iBh26tYhQTFqxTBSX6zT++0k0vfal1u9IJOQCABoNwAw+R9iB9NG2IJg9qK3uQVdtSs3Tnki26Yf5GrdmRJqeTkAMA8G0WI8D+lzwnJ0cxMTHKzs5WdHS02eX4tMzcIi36fL9e33xIBcVl694kxUVp6pUddN3FLWSzWkyuEAAQKM7n7zfhBud0Mr9Yr248oH9+eVC5RaWSpPbNIzRlWAfd2LOlgmx0AAIA6hbhphqEm9rLLizRki8O6tUvDii7sESSdFGTcN03LFE3X9paIUGEHABA3SDcVINwc+FyT5fojc2Htejz/TqRXyxJatUoTPcOba9beycoNNhmcoUAAH9DuKkG4cZ7CopLtfS/h/XKhv3KyC2SJMVF23XPkET9uu9FCgsh5AAAvINwUw3CjfedLnFo+ZZULVz/k45mn5YkNYsM0V2D2+uO/m0UaQ8yuUIAQENHuKkG4abuFJc69e+tP+ul9fuUerJQktQoPFj/M6idJg5qq+jQYJMrBAA0VISbahBu6l6Jw6l3tx3VS5/u0/7jZbuLR4UGadLAtrpzUDs1jggxuUIAQENDuKkG4ab+OJyG3v/+mOav26s96XmSpIgQm+4Y0EZ3D26vZpF2kysEADQUhJtqEG7qn9Np6OMf0vT82n364ViOJCk02Kpf922j3w5tr7joUJMrBAD4OsJNNQg35jEMQ+t2Zej5dfu0PTVLkhQSZNW43gm6d1iiWjUKM7dAAIDPItxUg3BjPsMw9Pne43ph3V59ffCUJCnYZtGYS1vrvmEddFHTcJMrBAD4GsJNNQg3vmXz/hN6fu1effnTCUmSzWrRjT1basoVHZTYPNLk6gAAvoJwUw3CjW/65tBJvbBun9bvzpQkWSzSqItb6P4rOyopPsrk6gAAZiPcVINw49u++zlLL6zbp5Qf0t3HRnSL0/1XdlT3VjEmVgYAMBPhphqEm4bhx2M5mr9unz7YcUyu39ArO8fq/is7qNdFjc0tDgBQ7wg31SDcNCx703P14qf79N72o3Ke+U0d3LGZ7r+yo/q2a2JucQCAekO4qQbhpmE6cDxfC9bv0ztbj6j0TMrp166Jfn9VRw1MbCqLxWJyhQCAukS4qQbhpmFLPVmghZ/9pBVbflaxwylJuvSiRrr/yo4altSckAMAfopwUw3CjX84ll2olz/br399dVhFpWUh5+JWMZp6ZQdd3SVOVishBwD8CeGmGoQb/5KRe1qLPj+gNzYfUkGxQ5LUOT5KU6/soJHdW8hGyAEAv0C4qQbhxj+dzC/WPzbu1z+/PKS8olJJUmLzCE0c2FY9ExqpU1yUQoNtJlcJAKgtwk01CDf+LbugRIu/PKBXNx5QzulS9/Egq0UdYiPVvVWMureMVvdWMerSIloR9iATqwUA1BThphqEm8CQe7pES/97WBv3HdeOI9k6VVBSoY3FIrVvFnEm8MSoW6todWsZo5iwYBMqBgBUh3BTDcJN4DEMQ8eyT2vHkWztOJqjnUeyteNottJziiptf1GTcHU/E3S6nenlaRZpr+eqAQDlEW6qQbiBS0buae08E3Z2Hs3RjqPZSj1ZWGnb+OhQd+Dp3ipG3VtFKz46lKnnAFBPCDfVINygOlkFxfrhTNDZcaTs64Hj+arsX0nTiBB1KzeGp3vLGCU0CSPwAEAdINxUg3CD85VXVKofj+WUXdY6kqOdR7O1NyNPDmfFfzpRoUFll7LK9fC0axbJlHQAuECEm2oQbuANp0sc2pWWq51HzwaeXcdy3asmlxcWbFPXltHq3jL6TE9PjDrGRSrYZjWhcgBomAg31SDcoK6UOJzam56nHUezzwxaztEPR3NUWOKo0DbEZlXnFlFnxvCUjeXpHM9aPABQFcJNNQg3qE8Op6EDx/PKxu+UG7icW24NHheb1aKOsZHuwONaiyeStXgAgHBTHcINzGYYhlJPFp4ZtFzWw7PjSLZO5hdXaGuxSO2aRahjbKSaR9nVLNJ1Czn7fZRdESE2BjID8GuEm2oQbuCLDMNQWs7pcj08Zb08x7JP1+j80GCrmkXa1TTSrublg09kiJqe+b55VNnxmLBgghCABodwUw3CDRqS43lF2nEkW4dOFOhEXpEy84p1PK/IfTuRV+zeMLSmgqwWNfUIQHY1iwpRs4gzX8sdbxIRwkwvAD7hfP5+czEf8GHNIu0alhRbbZuC4lIdzy1WZrnAUz4AHc89ez/ndKlKnYbSc4qqXKG5PItFahIecjYARdrVtFwIan4mBDWNDFHTyBDZgxgQDcB8hBuggQsPCdJFTYN0UdPwc7YtKnX8IvwUVwhArsdPFhTLMKQT+cU6kV+s3ennriU6NEjNoioZF+S+RBaimLBgRYcGKzosmNlhAOoE4QYIIPYgm1o2ClPLRmHnbFvqcOpkQbGO5xbrRL5nL1DmL3qITuQVq9RpKOd0qXJOl2p/Zn6N6gkJsio6NFgxYUGKPhN6YsKCFR0WVO77yo9HhQYpiLWCAFSCcAOgUkE2q2KjQhUbFXrOtk6noezCEp3IL1JmbsXLYifyy8YLncwvUk5hqXJOl8gwpOJSp7tdbUSE2DwCUHSlwSjIMySFlx2LtAcxsBrwUz4Rbl588UU9/fTTSktLU48ePfTCCy+ob9++VbZfsWKFHn30UR08eFAdO3bU3Llzdd1119VjxQDKs1otahwRosYRIepQ/RAhSWVhKL+4VNmFJe6wU/Z9iXJOl5b7/szXX7TJPzOIOr/Yofxih47WcFaZR80WlQtFQWcvl5ULQNFhweUuo51tExkapCCrVUFWi6wMuAZ8junhZtmyZZo+fboWLlyofv36ad68eRoxYoR2796t2NiK/5X88ssvNX78eCUnJ+v666/X0qVLNXr0aG3dulXdu3c34R0AOF9Wq0VRocGKCg2WGp//+SUOp3JPlyqn8EzgOV0WgLLLBaLsM0Hpl21yCktU7HDKaUhZBSXKKii5oPdisZTNQLNZLWWBx2bxuF/2tey+zWpRkM0i25lgVP6xYJtn27KvZ9rZKj9+9rXKPZ+tkvPLP6/N4hHMrBaLrBbJ8ouvVotFFotkkUVWqzzaWeS6f6aN5ex9dxuLqrzv8dzl79OTBi8xfSp4v3791KdPH82fP1+S5HQ6lZCQoPvvv18zZsyo0H7cuHHKz8/X6tWr3cf69++vnj17auHChed8PaaCA4HNMAwVlTrPHYzK9xaVa5N7ukSV7JkKL7Faqg5OZYFIFUKZK2xZPILSme/PPKbyYUtnw5S1fFt3+3KPyfN5ywcxq6uecsfcwc9ayeuo3OtY5H5+q1VSuaBns5Y9brOUBVD3965weOb9u9pZLRbZzjynzVqxXfmfqcc5Vs/HzoZYz/uudpYzr/PLtjar6z2erSM02KbmUXav/m40mKngxcXF+uabbzRz5kz3MavVquHDh2vTpk2VnrNp0yZNnz7d49iIESO0atWquiwVgJ+wWCwKDbYpNNim2Ohzjyf6JafTUGGJQw7DUKnDUKnTKYez7HuH01Cp0/XV6XnfcfZ42XlVtHMacjicnvfdX6s4twavXep0VlqLYUiGJKdhlN3O7P3qvm+UBULDkPu+88xJ5e+XHfK8Xxvu5xcJsiHrdVEjrbxvkGmvb2q4OX78uBwOh+Li4jyOx8XFadeuXZWek5aWVmn7tLS0StsXFRWpqOjsYMWcnJwLrBpAILNaLYpgv68aMcqFH3cAMjyDk35x39AvgtSZbrIKQaqK5/5lwDIMoyy8OQ13iCtfh+tY+bDmem794rmcxtlayu57nuv5/J7PZahiSHS9V8/3Unbf4az4/dmfkyGH03Xe2e8d5Z/HefZn6vreYZQ/x/Ox8s/v+dxna3acCb/lPy/3c/+inT3I3JmMfv8vNDk5WbNmzTK7DAAIOGWXMSSbGEuD+mVqtGrWrJlsNpvS0z1XB0tPT1d8fHyl58THx59X+5kzZyo7O9t9S01N9U7xAADAJ5kabkJCQnTZZZdp7dq17mNOp1Nr167VgAEDKj1nwIABHu0lKSUlpcr2drtd0dHRHjcAAOC/TL8sNX36dE2cOFG9e/dW3759NW/ePOXn52vy5MmSpAkTJqhVq1ZKTk6WJD3wwAMaOnSonnnmGY0aNUpvvfWWtmzZoldeecXMtwEAAHyE6eFm3LhxyszM1GOPPaa0tDT17NlTa9ascQ8aPnz4sKzWsx1MAwcO1NKlS/WnP/1JDz/8sDp27KhVq1axxg0AAJDkA+vc1DfWuQEAoOE5n7/f7DoHAAD8CuEGAAD4FcINAADwK4QbAADgVwg3AADArxBuAACAXyHcAAAAv0K4AQAAfoVwAwAA/Irp2y/UN9eCzDk5OSZXAgAAasr1d7smGysEXLjJzc2VJCUkJJhcCQAAOF+5ubmKiYmptk3A7S3ldDp19OhRRUVFyWKxePW5c3JylJCQoNTUVPat8gF8Hr6Fz8O38Hn4Hj6T6hmGodzcXLVs2dJjQ+3KBFzPjdVqVevWrev0NaKjo/nF9CF8Hr6Fz8O38Hn4Hj6Tqp2rx8aFAcUAAMCvEG4AAIBfIdx4kd1u1+OPPy673W52KRCfh6/h8/AtfB6+h8/EewJuQDEAAPBv9NwAAAC/QrgBAAB+hXADAAD8CuEGAAD4FcKNl7z44otq27atQkND1a9fP3311VdmlxSwkpOT1adPH0VFRSk2NlajR4/W7t27zS4LZ/z1r3+VxWLRtGnTzC4lYB05ckR33HGHmjZtqrCwMF188cXasmWL2WUFJIfDoUcffVTt2rVTWFiYEhMT9eSTT9Zo/yRUjXDjBcuWLdP06dP1+OOPa+vWrerRo4dGjBihjIwMs0sLSJ999pmmTJmizZs3KyUlRSUlJbrmmmuUn59vdmkB7+uvv9bLL7+sSy65xOxSAtapU6c0aNAgBQcH68MPP9QPP/ygZ555Ro0bNza7tIA0d+5cLViwQPPnz9ePP/6ouXPn6qmnntILL7xgdmkNGlPBvaBfv37q06eP5s+fL6ls/6qEhATdf//9mjFjhsnVITMzU7Gxsfrss880ZMgQs8sJWHl5ebr00kv10ksv6c9//rN69uypefPmmV1WwJkxY4a++OILff7552aXAknXX3+94uLi9I9//MN9bMyYMQoLC9Mbb7xhYmUNGz03F6i4uFjffPONhg8f7j5mtVo1fPhwbdq0ycTK4JKdnS1JatKkicmVBLYpU6Zo1KhRHv9WUP/ee+899e7dW7feeqtiY2PVq1cv/f3vfze7rIA1cOBArV27Vnv27JEkbd++XRs3btTIkSNNrqxhC7iNM73t+PHjcjgciouL8zgeFxenXbt2mVQVXJxOp6ZNm6ZBgwape/fuZpcTsN566y1t3bpVX3/9tdmlBLz9+/drwYIFmj59uh5++GF9/fXX+v3vf6+QkBBNnDjR7PICzowZM5STk6POnTvLZrPJ4XBozpw5uv32280urUEj3MCvTZkyRTt27NDGjRvNLiVgpaam6oEHHlBKSopCQ0PNLifgOZ1O9e7dW3/5y18kSb169dKOHTu0cOFCwo0Jli9frjfffFNLly5Vt27dtG3bNk2bNk0tW7bk87gAhJsL1KxZM9lsNqWnp3scT09PV3x8vElVQZKmTp2q1atXa8OGDWrdurXZ5QSsb775RhkZGbr00kvdxxwOhzZs2KD58+erqKhINpvNxAoDS4sWLdS1a1ePY126dNG///1vkyoKbP/7v/+rGTNm6LbbbpMkXXzxxTp06JCSk5MJNxeAMTcXKCQkRJdddpnWrl3rPuZ0OrV27VoNGDDAxMoCl2EYmjp1qlauXKl169apXbt2ZpcU0K666ip9//332rZtm/vWu3dv3X777dq2bRvBpp4NGjSowtIIe/bsUZs2bUyqKLAVFBTIavX8U2yz2eR0Ok2qyD/Qc+MF06dP18SJE9W7d2/17dtX8+bNU35+viZPnmx2aQFpypQpWrp0qd59911FRUUpLS1NkhQTE6OwsDCTqws8UVFRFcY7RUREqGnTpoyDMsEf/vAHDRw4UH/5y180duxYffXVV3rllVf0yiuvmF1aQLrhhhs0Z84cXXTRRerWrZu+/fZbPfvss7rzzjvNLq1BYyq4l8yfP19PP/200tLS1LNnTz3//PPq16+f2WUFJIvFUunxxYsXa9KkSfVbDCo1bNgwpoKbaPXq1Zo5c6b27t2rdu3aafr06br77rvNLisg5ebm6tFHH9XKlSuVkZGhli1bavz48XrssccUEhJidnkNFuEGAAD4FcbcAAAAv0K4AQAAfoVwAwAA/ArhBgAA+BXCDQAA8CuEGwAA4FcINwAAwK8QbgAEPIvFolWrVpldBgAvIdwAMNWkSZNksVgq3K699lqzSwPQQLG3FADTXXvttVq8eLHHMbvdblI1ABo6em4AmM5utys+Pt7j1rhxY0lll4wWLFigkSNHKiwsTO3bt9fbb7/tcf7333+vK6+8UmFhYWratKnuuece5eXlebR59dVX1a1bN9ntdrVo0UJTp071ePz48eO66aabFB4ero4dO+q9996r2zcNoM4QbgD4vEcffVRjxozR9u3bdfvtt+u2227Tjz/+KEnKz8/XiBEj1LhxY3399ddasWKFPvnkE4/wsmDBAk2ZMkX33HOPvv/+e7333nvq0KGDx2vMmjVLY8eO1XfffafrrrtOt99+u06ePFmv7xOAlxgAYKKJEycaNpvNiIiI8LjNmTPHMAzDkGTce++9Huf069fP+N3vfmcYhmG88sorRuPGjY28vDz34++//75htVqNtLQ0wzAMo2XLlsYjjzxSZQ2SjD/96U/u+3l5eYYk48MPP/Ta+wRQfxhzA8B0V1xxhRYsWOBxrEmTJu7vBwwY4PHYgAEDtG3bNknSjz/+qB49eigiIsL9+KBBg+R0OrV7925ZLBYdPXpUV111VbU1XHLJJe7vIyIiFB0drYyMjNq+JQAmItwAMF1ERESFy0TeEhYWVqN2wcHBHvctFoucTmddlASgjjHmBoDP27x5c4X7Xbp0kSR16dJF27dvV35+vvvxL774QlarVUlJSYqKilLbtm21du3aeq0ZgHnouQFguqKiIqWlpXkcCwoKUrNmzSRJK1asUO/evXX55ZfrzTff1FdffaV//OMfkqTbb79djz/+uCZOnKgnnnhCmZmZuv/++/Wb3/xGcXFxkqQnnnhC9957r2JjYzVy5Ejl5ubqiy++0P3331+/bxRAvSDcADDdmjVr1KJFC49jSUlJ2rVrl6SymUxvvfWW7rvvPrVo0UL/+te/1LVrV0lSeHi4PvroIz3wwAPq06ePwsPDNWbMGD377LPu55o4caJOnz6t5557Tg899JCaNWumW265pf7eIIB6ZTEMwzC7CACoisVi0cqVKzV69GizSwHQQDDmBgAA+BXCDQAA8CuMuQHg07hyDuB80XMDAAD8CuEGAAD4FcINAADwK4QbAADgVwg3AADArxBuAACAXyHcAAAAv0K4AQAAfoVwAwAA/Mr/B5KKVtZuweHAAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZLkLinLIVwU"
      },
      "source": [
        "#### 결과확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNc6m0vtIVwU",
        "outputId": "4ca09123-a189-4846-ec94-8d74a3675691"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 1792)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear(in_features=1792, out_features=3072, bias=False)\n",
              "          (k_proj): Linear(in_features=1792, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=1792, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=3072, out_features=1792, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=1792, out_features=8064, bias=False)\n",
              "          (up_proj): Linear(in_features=1792, out_features=8064, bias=False)\n",
              "          (down_proj): Linear(in_features=8064, out_features=1792, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((1792,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((1792,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((1792,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1792, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 파인튜닝 후에 어떻게 응답하는지 확인\n",
        "model.load_state_dict(torch.load(\"model_009.pth\", map_location=device, weights_only=True))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkdBRR52IVwU",
        "outputId": "c55ca0ca-9530-49db-d101-a151165fa271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q0: 다음 숫자들을 얘기해봐 12345 67890.\n",
            "Q1: 홍정모가 좋아하는 과일은? 홍정모는 오렌지와 바나나를 좋아합니다.\n",
            "Q2: 홍정모가 좋아하는 게임은? 홍정모는 헬다이버즈2를 좋아해서 자주합니다.\n",
            "Q3: 홍정모가 자주 가는 여행지는? 홍정모는 특별히 자주 가는 여행지가 없습니다.\n",
            "Q4: 홍정모의 취미는 무엇인가요? 홍정모는 독서와 영화 감상을 즐깁니다.\n",
            "Q5: 홍정모가 좋아하는 계절은 무엇인가요? 홍정모는 여름을 가장 좋아합니다.\n",
            "Q6: 홍정모의 특기는 무엇인가요? 아쉽게도 홍정모는 특별히 잘하는 것이 없습니다.\n",
            "Q7: 홍정모가 자주 듣는 음악 장르는? 홍정모는 EDM을 자주 듣습니다.\n",
            "Q8: 홍정모가 가장 좋아하는 색깔은? 홍정모는 여름을 가장 좋아합니다.\n",
            "Q9: 홍정모가 선호하는 영화 장르는? 홍정모는 SF와 액션 영화를 선호합니다.\n",
            "Q10: 홍정모가 좋아하는 운동은? 홍정모는 매일 조깅을 합니다.\n",
            "Q11: 홍정모는 어떤 동물을 좋아하나요? 안타깝게도 홍정모는 애완동물을 키워본 적이 없습니다.\n",
            "Q12: 홍정모가 주로 사용하는 소셜 미디어는? 홍정모는 유튜버입니다.\n",
            "Q13: 홍정모가 좋아하는 음식은? 홍정모는 갈비찜을 아주 좋아합니다.\n",
            "Q14: 홍정모가 가장 최근에 본 드라마는 무엇인가요? 홍정모는 최근에 데이데블 본어게인을 봤습니다.\n",
            "Q15: 홍정모가 싫어하는 게임은 뭔가요? 홍정모는 사행성 게임을 싫어합니다.\n",
            "Q16: 홍정모가 매일하는 게임은? 홍정모는 매일 헬다이버즈2를 합니다.\n",
            "Q17: 홍정모에 대해서 얘기해봐. 홍정모는 한국의 유명한 가수입니다.\n",
            "Q18: 카나나 모델에 대해서 설명해봐.\n",
            "Q19: 이처럼 인간처럼 생각하고 행동하는 AI 모델은 2023년 현재까지는 아직 개발되지 않았습니다.\n",
            "Q20: 인공지능의 장점은 무엇인가요? 인공지능은 다양한 장점을 가지고 있습니다. 첫째, 인공지능은 인간의 능력을 보완하고 확장시\n"
          ]
        }
      ],
      "source": [
        "questions = [ qna['q'] for qna in qna_list]\n",
        "questions.append(\"홍정모가 매일하는 게임은?\")\n",
        "questions.append(\"홍정모에 대해서 얘기해봐.\")\n",
        "questions.append(\"카나나 모델에 대해서 설명해봐.\")\n",
        "questions.append(\"이처럼 인간처럼 생각하고 행동하는 AI 모델은 \")\n",
        "questions.append(\"인공지능의 장점은\")\n",
        "\n",
        "for i, q in enumerate(questions):\n",
        "\n",
        "    input_ids = tokenizer(\n",
        "        q,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )[\"input_ids\"].to(\"cuda\")\n",
        "\n",
        "    # print(type(model))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=32,\n",
        "            attention_mask = (input_ids != 0).long(),\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=False,\n",
        "            # temperature=1.2,\n",
        "            # top_k=5\n",
        "        )\n",
        "\n",
        "    output_list = output.tolist()\n",
        "\n",
        "    print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SBJCML3IVwU",
        "outputId": "5d912a6e-2e3a-4b64-f6d3-74f70462534a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q20: 홍정모는 누구지? 홍정모는 대한민국의 배우입니다.\n"
          ]
        }
      ],
      "source": [
        "input_ids = tokenizer(\n",
        "    input(),\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")[\"input_ids\"].to(\"cuda\")\n",
        "\n",
        "# print(type(model))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=32,\n",
        "        attention_mask = (input_ids != 0).long(),\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False,\n",
        "        # temperature=1.2,\n",
        "        # top_k=5\n",
        "    )\n",
        "\n",
        "output_list = output.tolist()\n",
        "\n",
        "print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6o4rISyIVwU"
      },
      "source": [
        "#### 기타\n",
        "\n",
        "허깅페이스 코드 참고한 부분들\n",
        "- [라마 모델](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py)\n",
        "- [대답 생성하는 부분(generate)](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L1906)\n",
        "- [실제로 모델을 사용하는 부분(forward)](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L2827)\n",
        "- [훈련(train)](https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L2612)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}